{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a878b184-c44d-4572-b817-db47549a65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from panns_inference import AudioTagging, SoundEventDetection, labels\n",
    "import whisper\n",
    "\n",
    "\n",
    "def find_audios(parent_dir, exts=['.wav', '.mp3', '.flac', '.webm', '.mp4', '.m4a']):\n",
    "    audio_files = []\n",
    "    for root, dirs, files in os.walk(parent_dir):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1] in exts:\n",
    "                audio_files.append(os.path.join(root, file))\n",
    "    return audio_files\n",
    "\n",
    "\n",
    "#################### PANNs ####################\n",
    "\n",
    "def load_panns(device='cuda'):\n",
    "    model = AudioTagging(checkpoint_path=None, device=device)\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def tag_audio(model, audio_path):\n",
    "    (audio, _) = librosa.core.load(audio_path, sr=32000, mono=True)\n",
    "    # only use the first 30 seconds\n",
    "    audio = audio[None, :30*32000]\n",
    "    (clipwise_output, embedding) = model.inference(audio)\n",
    "    tags, probs = get_audio_tagging_result(clipwise_output[0])\n",
    "    return tags, probs\n",
    "\n",
    "\n",
    "def get_audio_tagging_result(clipwise_output):\n",
    "    \"\"\"Visualization of audio tagging result.\n",
    "    Args:\n",
    "      clipwise_output: (classes_num,)\n",
    "    \"\"\"\n",
    "    sorted_indexes = np.argsort(clipwise_output)[::-1]\n",
    "\n",
    "    tags = []\n",
    "    probs = []\n",
    "    for k in range(10):\n",
    "        tag = np.array(labels)[sorted_indexes[k]]\n",
    "        prob = clipwise_output[sorted_indexes[k]]\n",
    "        tags.append(tag)\n",
    "        probs.append(float(prob))\n",
    "\n",
    "    return tags, probs \n",
    "\n",
    "\n",
    "def is_vocal(tags, probs, threshold=0.08):\n",
    "    pos_tags = {'Speech', 'Singing', 'Rapping'}\n",
    "    for tag, prob in zip(tags, probs):\n",
    "        if tag in pos_tags and prob > threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "#################### Whisper ####################\n",
    "\n",
    "\n",
    "def load_whisper(model=\"large\"):\n",
    "    model = whisper.load_model(model, in_memory=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def transcribe_and_save(whisper_model, panns_model, args):\n",
    "    \"\"\"transcribe the audio, and save the result with the same relative path in the output_dir\n",
    "    \"\"\"\n",
    "    audio_files = find_audios(args.input_dir)\n",
    "\n",
    "    if args.n_shard > 1:\n",
    "        print(f'processing shard {args.shard_rank} of {args.n_shard}')\n",
    "        audio_files.sort() # make sure no intersetction\n",
    "        audio_files = audio_files[args.shard_rank * len(audio_files) // args.n_shard : (args.shard_rank + 1) * len(audio_files) // args.n_shard] \n",
    "\n",
    "    for file in tqdm(audio_files):\n",
    "        output_file = os.path.join(args.output_dir, os.path.relpath(file, args.input_dir))\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        result = {}\n",
    "        try:\n",
    "            tags, probs = tag_audio(panns_model, file)\n",
    "\n",
    "            if args.threshold == 0. or is_vocal(tags, probs, threshold=args.threshold):\n",
    "                if args.debug:\n",
    "                    print(file)\n",
    "                    for tag, prob in zip(tags, probs):\n",
    "                        print(f'{tag}: {prob}')\n",
    "                    continue\n",
    "                \n",
    "                result = whisper.transcribe(whisper_model, file, language=args.language, initial_prompt=args.prompt)\n",
    "                result['tags_with_probs'] = [{'tag': tag, 'prob': prob} for tag, prob in zip(tags, probs)]\n",
    "                with open(output_file + '.json', 'w') as f:\n",
    "                    json.dump(result, f, indent=4, ensure_ascii=False)\n",
    "            else:\n",
    "                print(f'no vocal in {file}')\n",
    "                if args.debug:\n",
    "                    for tag, prob in zip(tags, probs):\n",
    "                            print(f'{tag}: {prob}')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69bc222c-ead5-45f3-ae3f-e8c2722e96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    model = 'large-v3'\n",
    "    prompt = 'lyrics: '\n",
    "    language = 'vi'\n",
    "    input_dir = './sample'\n",
    "    output_dir = './results'\n",
    "    n_shard = 1\n",
    "    shard_rank = 0\n",
    "    threshold = 0\n",
    "    debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36fdf3e-4fab-4157-ac29-a7cad438b974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: /home/kelvinsoh/panns_data/Cnn14_mAP=0.431.pth\n",
      "GPU number: 1\n"
     ]
    }
   ],
   "source": [
    "whisper_model = load_whisper(args.model)\n",
    "panns_model = load_panns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee3096f7-a6e5-4c74-b9d5-353d416cc5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 2/2 [00:16<00:00,  8.09s/it]\n"
     ]
    }
   ],
   "source": [
    "transcribe_and_save(whisper_model, panns_model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2d5b093-355c-4258-b20a-c94fd09e76f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn Hãy subscribe cho kênh Ghiền Mì Gõ Để không bỏ lỡ những video hấp dẫn\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Open the JSON file\n",
    "with open('CustomLyricWhiz/results/0 Giờ 2 Phút.mp3.json', 'r') as file:\n",
    "    # Load the JSON data\n",
    "    data = json.load(file)\n",
    "\n",
    "# Now 'data' contains the content of the JSON file\n",
    "print(data['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nus",
   "language": "python",
   "name": "nus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
