{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RENDER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_timestamp(seconds_start, seconds_end):\n",
    "    # Convert the start timestamp to minutes and seconds    \n",
    "    minutes_start = int(seconds_start // 60)\n",
    "    seconds_start_remainder = seconds_start % 60\n",
    "    \n",
    "    # Format the start timestamp to MM:SS.SS\n",
    "    formatted_start = f\"{minutes_start:02}:{seconds_start_remainder:05.2f}\"\n",
    "    \n",
    "    # Convert the end timestamp to minutes and seconds (optional if needed)\n",
    "    minutes_end = int(seconds_end // 60)\n",
    "    seconds_end_remainder = seconds_end % 60\n",
    "    \n",
    "    # Format the end timestamp to MM:SS.SS (optional if needed)\n",
    "    formatted_end = f\"{minutes_end:02}:{seconds_end_remainder:05.2f}\"\n",
    "    \n",
    "    # Return the formatted string\n",
    "    return f\"[{formatted_start}]\"\n",
    "\n",
    "def split_combined_word(word):\n",
    "    # Use regular expression to split at the capital letter in the middle\n",
    "    split_words = re.findall(r'[a-z]+|[A-Z][a-z]*', word)\n",
    "    return split_words\n",
    "\n",
    "def chunk_lyrics(chunks, segment_length=20):\n",
    "    \"Chunk the lyrics into 30-second chunks, 0.5 seconds overlap.\"\n",
    "    # chunks = [chunks[i:i+segment_length] for i in range(0, len(chunks), segment_length)]\n",
    "    start_sec = 0\n",
    "    output_chunks = []\n",
    "    \n",
    "    output_dict = {\n",
    "        'text': '',\n",
    "        'timestamp': [],\n",
    "    }\n",
    "\n",
    "    for index,  text_dict in enumerate(chunks):\n",
    "        start_sec = text_dict['timestamp'][0]\n",
    "        end_sec = text_dict['timestamp'][1]\n",
    "\n",
    "        if index == 0: start_of_chunk = text_dict['timestamp'][0]\n",
    "        \n",
    "        end_of_chunk = start_of_chunk + segment_length\n",
    "\n",
    "        if index == 0:\n",
    "            output_dict['text'] += text_dict['text'] + ' '\n",
    "            output_dict['timestamp'] = [start_sec, end_sec]\n",
    "\n",
    "        elif index == len(chunks) - 1:\n",
    "            output_dict['text'] += text_dict['text']\n",
    "            output_dict['timestamp'][1] = end_sec\n",
    "            output_chunks.append(output_dict)\n",
    "            \n",
    "        elif end_of_chunk >= end_sec:\n",
    "            output_dict['text'] += text_dict['text'] + ' '\n",
    "            output_dict['timestamp'][1] = end_sec\n",
    "        \n",
    "        else:\n",
    "            temp_dict = output_dict.copy()\n",
    "            output_chunks.append(temp_dict)    \n",
    "            #Reset\n",
    "            output_dict['text'] = text_dict['text'] + ' '\n",
    "            output_dict['timestamp'] = [start_sec, end_sec]\n",
    "            start_of_chunk = start_sec\n",
    "            \n",
    "    \n",
    "    return output_chunks\n",
    "    \n",
    "def output_render(\n",
    "    json_result,\n",
    "    format: str = 'phowhisper',\n",
    "    ):\n",
    "\n",
    "    if format == 'phowhisper':\n",
    "        render_output = []\n",
    "        for text_dict in json_result:\n",
    "            cur_text = convert_timestamp(text_dict['timestamp'][0], text_dict['timestamp'][1]) + ' ' + text_dict['text']\n",
    "            render_output.append(cur_text)\n",
    "\n",
    "        render_output = '\\n'.join(render_output)\n",
    "\n",
    "    elif format == 'whisper':\n",
    "        chunks = json_result['chunks']\n",
    "        chunks = chunk_lyrics(chunks, segment_length=30)\n",
    "        render_output = output_render(\n",
    "            chunks,\n",
    "            format='phowhisper'\n",
    "        )\n",
    "    \n",
    "    \n",
    "    return render_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:29.98] Bài  Hát  Cuối  Ca  Sĩ  &  Đàn  Ông  HồngNgười  ra  điEm  theo  anh  về  Quảng  Ngãi  một  lần  được  không \n",
      "[00:58.78]  Qua  cầu  Bổ  Ly  Trưa  nắng  hạ  là  nước  long  lanh  Ngồi  kề  bên  anh  Nôn  nao  ngắm  ngó  Thương  sao  đất  lành  Đi  qua  nghĩa  hạnh  Qua  sơn  tình  tư  nghĩa  mộng  mơ  Chiều  bến  Tam  Thương  Thương  sông \n",
      "[01:28.78]  Trà  hàng  ghế  che  bờ  Đẹp  tình  ba  tơ  Thương  sông  núi  Minh  Long  Sơn  Hà  Em  theo  anh  qua  những  con  đường  Mang  bao  di  tích  đời  đời  Quê  tôi  mồ  đực  đây  rồi  Chiều  quê \n",
      "[01:58.08]  chiều  quê  Thương  ai  ai  cấy  mà  non  Thương  anh  Thương  anh  Quảng  Ngãi  em  về  Sơn  tay  giữ  mãi  câu  thề  Trà  Bồng  dịu  dàng  nắng  trong  Bình  Sơn  Yêu  sao  tiếng  hát  nhớ  nhau  Thương  anh  Em  về  cùng \n",
      "[02:27.68]  anh  Qua  bao  năm  xuôi  ngược  Nay  trở  về  Quảng  Ngãi  quê  tôi  Qua  Lý  Sơn  xưa  Nay  thuyền  bè  sum  đúc  đôi  bờ  Đức  Phố  mẹ  tôi  Còn  đứng  đó  trong  đợi  con  về  Quảng  Ngãi  mẹ  tôi \n",
      "[02:56.92]  Còn  đứng  đó  trong  đợi  con \n",
      "[03:00.20]  vềNgười  ơi  em  có  biết  Bao  nhi \n",
      "[03:44.40]  một  lần  được  không  Qua  cầu  Bổ  Lũy  Trưa  nắng  hạ  làng  nước  long  lanh  Ngồi  kề  bên  anh  Nôn  nao  ngắm  ngó  Thương  sao  đất  lành  Đi  qua  Nghĩa  Hành  Qua  Sơn  tình  tư  nghĩa  mộng  mơ  Chiều  bến  tang \n",
      "[04:14.38]  thương  Thương  sông  Trà  Hàng  ghế  che  bờ  Đẹp  tình  ba  cơ  Thương  sông  núi  Mênh  long  sơn  hà  Em  theo  anh  qua  những  con  đường  Mang  bao  di  tích  đời  đời  Quê  tôi  mồ  đực  đây  rồi \n",
      "[04:44.02]  Chiều  quê  chiều  quê  Thương  ai  ai  cấy  mà  non  Thương  anh  thương  anh  Quảng  Ngãi  em  về  Sơn  tay  giữ  mãi  câu  thề  Trà  Bồng  dịu  dàng  nắng  trongình  Sơn  Yêu  sao  tiếng  hát  nhớ  nhau  Thương  anh  thương  anh \n",
      "[05:13.92]  Em  về  cùng  anh  Qua  bao  năm  xuôi  ngược  Nay  trở  về  Quảng  Ngãi  quê  tôi  Qua  Lý  Sơn  xưa  Nay  Thuyền  Bè  sum  đúc  đôi  bờ  Đức  Phố  mẹ  tôi \n",
      "[05:38.96]  Còn  đứng  đó  trong  đời  con  về  Quảng  Ngãi  mẹ  tôi  Còn  đứng  đó  trong  đời  con  về\n"
     ]
    }
   ],
   "source": [
    "# phowhisper_output = '/home/anh/Documents/vietnamese-song-scraping/out/PhoWhisper-small/validation-audio-100-pp_nospeech-remove/Ai Về Quảng Ngãi.mp3.json'\n",
    "\n",
    "output = '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test-utf8/Ai Về Quảng Ngãi.json'\n",
    "with open(output, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "rendered_output = output_render(data, format='whisper')\n",
    "print(rendered_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CORRECTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anh/miniconda3/envs/vnmese_transcription/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.llm_corrector import load_llm, generate_corrections\n",
    "from glob import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = load_llm('gemini-1.0-pro-latest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 581.16it/s]\n"
     ]
    }
   ],
   "source": [
    "original_lyrics = glob('/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/*.json')\n",
    "\n",
    "original_lyrics = ['/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Tình Xa Ngàn Khơi.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Em Đã Thương Người Ta Hơn Anh.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Giấc Mơ Nồng.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Đồ Ngốc Anh Yêu Em.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Hen Gặp Lại Trong Chiêm Bao.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Sợ Bắt Đầu.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Giấc Mơ Mình Em.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Có Những Yêu Thương Nào.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Ánh Trăng Bên Thềm.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Chút Nắng Cuối Đông.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Vì Có Khi Đôi Tay.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Anh Nhớ Em Nhiều Lắm.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Ngoảnh Mặt.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Dâng Mẹ Quan Thế Âm.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Little Sài Gòn.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Giữa Hai Vì Sao.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Đạo Hiếu Vu Lan.json', '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test/Yêu Mãi.json']\n",
    "\n",
    "dest_dir = '/home/anh/Documents/vietnamese-song-scraping/out/whisper-large-v2-100-output-test-txt'\n",
    "os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "sexy_files = []\n",
    "\n",
    "for original_lyric in tqdm.tqdm(original_lyrics):\n",
    "    with open(original_lyric, 'r') as f:\n",
    "        transcription_result = json.load(f)\n",
    "\n",
    "    dest_file = os.path.basename(original_lyric).replace('.json', '.txt')\n",
    "    dest_file = os.path.join(dest_dir, dest_file)\n",
    "    if os.path.exists(dest_file):\n",
    "        continue\n",
    "    \n",
    "    transcription_result = output_render(transcription_result,format = 'whisper')\n",
    "    # try:\n",
    "    #     transcription_result = generate_corrections(llm_model, transcription_result)\n",
    "\n",
    "\n",
    "    # except:\n",
    "    #     print(f'failed to correct {original_lyric}')\n",
    "    #     sexy_files.append(original_lyric)\n",
    "    #     continue\n",
    "    \n",
    "    with open(dest_file, 'w') as f:\n",
    "        f.write(transcription_result)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnmese_transcription",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
