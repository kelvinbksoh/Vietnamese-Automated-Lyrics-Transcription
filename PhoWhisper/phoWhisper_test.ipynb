{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anh/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "No speecch from https://github.com/huggingface/transformers/issues/29595\n",
    "\n",
    "We found that the proba-\n",
    "bility of the <|nospeech|> token alone is not sufficient\n",
    "to distinguish a segment with no speech, but combining\n",
    "the no-speech probability threshold of 0.6 and the average\n",
    "log-probability threshold of −1 makes the voice activity\n",
    "detection of Whisper more reliable.\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# Load the processor and model\n",
    "model_name = \"vinai/PhoWhisper-small\"\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_possible_overlaps(transcriptions, maximum_overlapping_tokens = 5):\n",
    "    cleaned_transcriptions = []\n",
    "\n",
    "    for i, current in enumerate(transcriptions):\n",
    "        if i == 0:\n",
    "            # Add the first segment without changes\n",
    "            cleaned_transcriptions.append(current)\n",
    "            continue\n",
    "        \n",
    "\n",
    "        previous_text = cleaned_transcriptions[-1]['text'].split(' ')\n",
    "        previous_text[-1] = previous_text[-1][:-1] if previous_text[-1][-1] == '.' else previous_text[-1]\n",
    "        current_text  = current['text'].split(' ')\n",
    "\n",
    "        for j in range(8):\n",
    "            prev_tokens = previous_text[-j-1:]\n",
    "            cur_tokens  = current_text[:j+1]\n",
    "            if prev_tokens == cur_tokens:\n",
    "                # Matched\n",
    "                current_text = current_text[j+1:]\n",
    "                break\n",
    "\n",
    "        current['text'] = ' '.join(current_text)\n",
    "        cleaned_transcriptions.append(current)\n",
    "\n",
    "    return cleaned_transcriptions\n",
    "\n",
    "\n",
    "def chunk_audio(audio_path, sample_rate=16000, segment_length=30, overlap = 1.):\n",
    "    \"\"\"Load and split audio into 30-second chunks, 0.5 seconds overlap.\"\"\"\n",
    "    audio, _ = librosa.load(audio_path, sr=sample_rate, mono=True)\n",
    "\n",
    "    # Calculate the number of samples per segment and the overlap in samples\n",
    "    num_samples = segment_length * sample_rate\n",
    "    overlap_samples = int(overlap * sample_rate)\n",
    "\n",
    "    # Create the chunks with overlap\n",
    "    chunks = [\n",
    "        audio[i:i + num_samples] \n",
    "        for i in range(0, len(audio) - overlap_samples, num_samples - overlap_samples)\n",
    "    ]\n",
    "\n",
    "    chunk_timestamps = [(i/sample_rate, (i + num_samples)/ float(sample_rate)) for i in range(0, len(audio) - overlap_samples, num_samples - overlap_samples)]\n",
    "\n",
    "    return chunks, sample_rate, chunk_timestamps\n",
    "\n",
    "def transcribe_chunk(chunk, processor, model, no_speech_threshold=0.6, logprob_threshold=-1.0):\n",
    "    input_features = processor(chunk, sampling_rate=16000, return_tensors=\"pt\").input_features.to(\"cuda\")\n",
    "\n",
    "    # Generate transcription with VAD filtering\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(\n",
    "            input_features,\n",
    "            output_scores=True,\n",
    "            return_dict_in_generate=True,\n",
    "            max_new_tokens=400,\n",
    "            no_speech_threshold=no_speech_threshold,\n",
    "            logprob_threshold=logprob_threshold,\n",
    "            temperature= (0.4 - 0.7)\n",
    "        )\n",
    "    \n",
    "    # Decode and collect no-speech probability and log-probability information\n",
    "    decoded_text = processor.batch_decode(predicted_ids.sequences, skip_special_tokens=True)[0]\n",
    "    return {\n",
    "        \"text\": decoded_text\n",
    "    }\n",
    "\n",
    "\n",
    "def transcribe_full(audio_path, processor, model, segment_length=30, no_speech_threshold=0.6, logprob_threshold=-1.0):\n",
    "    # Chunk the audio\n",
    "    chunks, _, timestamps = chunk_audio(audio_path, segment_length=segment_length)\n",
    "\n",
    "    all_segments = []\n",
    "    for index, chunk in enumerate(chunks):\n",
    "        # Transcribe each chunk and gather segment details\n",
    "        segment = transcribe_chunk(chunk, processor, model, no_speech_threshold, logprob_threshold)\n",
    "        segment['timestamp'] = [timestamps[index][0], timestamps[index][1]]\n",
    "        all_segments.append(segment)\n",
    "\n",
    "    all_segments = remove_possible_overlaps(all_segments)\n",
    "\n",
    "    return all_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anh/.local/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:777: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_scores` is. When `return_dict_in_generate` is not `True`, `output_scores` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed Text:\n",
      "[{'text': 'giọng hồng cao cả.', 'timestamp': [0.0, 30.0]},\n",
      " {'text': 'ngắt nhẹ nhàng thoải lan làm sao lòng ta luôn nặng chiều bàn tay '\n",
      "          'ngày anh đã yếu giữ lấy sao lại buồn có phải tình cảm đáng nhớ sơ '\n",
      "          'hành nói đi đừng ai ngờ tại sao hai người nhắn thắc lại nước mắt '\n",
      "          'của tôi.',\n",
      "  'timestamp': [29.0, 59.0]},\n",
      " {'text': 'tại sao hai người khước đi những tháng ngày hạnh phúc giờ trong tôi '\n",
      "          'là bấm đêm đang phải cuối những nỗi đau lòng tôi thấy ân hận đôi mí '\n",
      "          'sưng sững lúc không giờ hài phố đến bên tôi vui đùa rồi xem tôi chỉ '\n",
      "          'là một kẻ dư thương trái tim tôi đã lầm khi yêu long em sắp ê nhìn.',\n",
      "  'timestamp': [58.0, 88.0]},\n",
      " {'text': 'những người đau khổ điều thức cùng nước mắt ngón sốc trong thâm tâm '\n",
      "          'này không thể ta nói yêu thương cho nhiều giờ đây anh hiểu ra bao '\n",
      "          'nhiêu điều suốt tình anh dễ dàng để đến từng vài ai những người '\n",
      "          'hạnh phúc đều thật yên giấc còn mối riêng anh ngay lại không chợt '\n",
      "          'mắt.',\n",
      "  'timestamp': [87.0, 117.0]},\n",
      " {'text': 'đường chớp mắt tại sao hai người nhận thân ngày muộn mất của tôi.',\n",
      "  'timestamp': [116.0, 146.0]},\n",
      " {'text': 'tại sao hai người cướp đi những tháng ngày hạnh phúc giờ trong tôi '\n",
      "          'là bóng đêm đang vây quanh những nỗi đau lòng tôi thấy ân hận đòi '\n",
      "          'mi dừng dừng lúc không giờ hạnh phúc bên bên tôi vui ừa rồi sang '\n",
      "          'tôi chỉ là một kẽ sư thường trái tim tôi đã lầm ý nghĩ rằng em sát '\n",
      "          'điêu nhưng đã bao lâu rồi hay thắc nhận và nhắn nhắn muốn nhắn nhắn '\n",
      "          'mình yêu thương nhắn.',\n",
      "  'timestamp': [145.0, 175.0]},\n",
      " {'text': 'những người đau khổ điều thức cùng nước mắt ngón sốc trong thâm tâm '\n",
      "          'này không thể tạo nói yêu thương cho nhiều giờ đây anh hiếu xá bao '\n",
      "          'nhiêu điều xua tên anh dễ dàng đến đến cùng bên ai những người hạnh '\n",
      "          'phúc đều thật yên giấc còn mỗi giếng anh nơi này không chà chang.',\n",
      "  'timestamp': [174.0, 204.0]},\n",
      " {'text': 'không chợt mà lại một đêm nữa khi mà cả thế giới đã thắt ngọn đèn '\n",
      "          'còn xương anh ngồi đay thấp sang giờ đây đã kết thúc hết tất cả '\n",
      "          'những chuyện đã qua em bước tiếp con đường hạnh phúc đi.',\n",
      "  'timestamp': [203.0, 233.0]},\n",
      " {'text': 'đừng nhìn lại.', 'timestamp': [232.0, 262.0]}]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "audio_path = \"sample/0 Giờ 2 Phút.mp3\"\n",
    "result = transcribe_full(audio_path, processor, model)\n",
    "\n",
    "# Print the final filtered transcription\n",
    "print(\"Transcribed Text:\")\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcriptions = [\n",
    "#     {'text': 'những người đau khổ điều thức cùng nước mắt ngon sốc trong thâm tâm '\n",
    "#              'này không thể tạo nó yêu thương cho nhiều giờ đây anh hiểu ra bao '\n",
    "#              'nhiêu điều suốt tên anh dễ dàng để đến từng vậy ai những người hạnh '\n",
    "#              'phúc đều thật yên giấc còn mối riêng anh ơi là không chợt mắt.',\n",
    "#      'timestamp': [87.0, 117.0]},\n",
    "#     {'text': 'không chợt mắt à à tại sao hai người nhận thân ngày muộn mất của tôi.',\n",
    "#      'timestamp': [116.0, 146.0]},\n",
    "#     {'text': 'tại sao hai người cướp đi những tháng ngày hạnh phúc giờ trong tôi '\n",
    "#              'là bướm em đang vây quanh những nỗi đau lòng tôi thấy ân hận đôi mi '\n",
    "#              'dừng dừng lúc không giờ hạnh phúc đến đêm tôi vui tựa dồi sáng tôi '\n",
    "#              'chỉ là một kẻ dữ thừa trái tim tôi đã lầm ý hiếu sanh em sát tiểu.',\n",
    "#      'timestamp': [145.0, 175.0]},\n",
    "# ]\n",
    "\n",
    "# new_transcriptions = remove_possible_overlaps(transcriptions)\n",
    "# pprint.pprint(new_transcriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
